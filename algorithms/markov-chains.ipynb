{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Markov Chains\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "\n",
    "random.seed('Markov')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chain Basics\n",
    "\n",
    "* [Useful DataCamp article](https://www.datacamp.com/community/tutorials/markov-chains-python-tutorial)\n",
    "* [Markov chain visualisation](http://setosa.io/ev/markov-chains)\n",
    "\n",
    "Using Markov chains assumes that the process being modelled has the [Markov Property](https://en.wikipedia.org/wiki/Markov_property). This means that:\n",
    "\n",
    "* The process is memoryless - any state beyond the current one isn't taken into account.\n",
    "* The process is stochastic - each state has a distribution of probabilities of what the next state's going to be.\n",
    "    * This distribution can include the current state.\n",
    "    * The distribution can also depend on the time elapsed (discrete-time Markov chain).\n",
    "\n",
    "If the distribution function can be identified then it can be used to predict future outcomes. This type of Markov chain is generally referred to as a '*Discrete Time Markov Chain*'. The 'discrete time' in the name here refers to the current state of the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What're Markov Chains Good For?\n",
    "\n",
    "As it's a stochastic method, Markov chains are most suitable for describing general *trends* rather than a specific future."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vocabulary\n",
    "\n",
    "* [Reducibility](https://en.wikipedia.org/wiki/Markov_chain#Reducibility) - if any state of the chain can lead to *any* other state.\n",
    "    * Another relevant term here is *accessible* - what states are accessible from a given state.\n",
    "* [Periodicity](https://en.wikipedia.org/wiki/Markov_chain#Periodicity) - if a state can only occur in multiples of *k* time steps it is referred to as *periodic*.\n",
    "    * This requires a fairly specific setup of the probability distribution, rather than requiring any sort of memory.\n",
    "    * If the period of a state is 1 then the state is *aperiodic*.\n",
    "* [Transience & Recurrence](https://en.wikipedia.org/wiki/Markov_chain#Transience_and_recurrence)\n",
    "    * A *transient* state is one where there's a non-zero chance we never return to it.\n",
    "    * A state that's not transient is *recurrent*.\n",
    "    * [Absorbing State](https://en.wikipedia.org/wiki/Markov_chain#Absorbing_states) - Any state it's impossible to leave.\n",
    "* [Ergodicity](https://en.wikipedia.org/wiki/Markov_chain#Ergodicity) - A state is *ergotic* if it isn't periodic and is recurrent.\n",
    "    * If every state in the chain is ergotic, the chain can also be described as ergotic.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Markov Chains With Text\n",
    "\n",
    "* [Simple but clever methodology](https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6)\n",
    "\n",
    "One of the most well-known uses of Markov chains is to generate semi-recognisable nonsense based on an input text. The process is basically broken down into two parts:\n",
    "\n",
    "1. Decomposing the text into a set of probabilities.\n",
    "2. Using those probabilities to piece together an output one word at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decomposing the text:\n",
    "\n",
    "This methodology comes from [this blog](https://towardsdatascience.com/simulating-text-with-markov-chains-in-python-1a27e6d13fc6) and I quite like it for this purpose. While storing the probabilities as lists might be a bit wasteful in terms of duplicates it alleviates the requirement for a massive matrix full of 0s for all of the rarely-used words. It also makes the generation step much more transparent. There might be some way to clean this up further with the ````collections```` library but this seems to perform well enough as-is.\n",
    "\n",
    "Another 'feature' of this methodology is to use the punctuation already in the text in situ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_word_dict(source_text : str) -> dict:\n",
    "    corpus = source_text.split()\n",
    "    pairs = make_pairs(corpus)\n",
    "    word_dict = {}\n",
    "    \n",
    "    for word_1, word_2 in pairs:\n",
    "        if word_1 in word_dict.keys():\n",
    "            word_dict[word_1].append(word_2)\n",
    "        else:\n",
    "            word_dict[word_1] = [word_2]\n",
    "    \n",
    "    return word_dict\n",
    "\n",
    "\n",
    "def make_pairs(corpus):\n",
    "    for i in range(len(corpus)-1):\n",
    "        yield (corpus[i], corpus[i+1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating an Output\n",
    "\n",
    "Using the dictionary of words above we can easily run through a chain of words:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def markov_output(word_dict : dict, n_words : int = 40) -> str:\n",
    "    \n",
    "    chain = [random.choice(list(word_dict.keys()))]\n",
    "\n",
    "    for i in range(n_words):\n",
    "        chain.append(random.choice(word_dict[chain[-1]]))\n",
    "\n",
    "    return ' '.join(chain)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_file = os.path.join(os.path.split(os.getcwd())[0],\n",
    "                           'data', 'the-hound-of-the-baskervilles.md'\n",
    "                          )\n",
    "source_text = open(source_file, encoding='utf8').read()\n",
    "\n",
    "words = create_word_dict(source_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "come. It was glad that he had reached the consent of the man in the evening before, for one of some clandestine appointment. So it is, Mr. Sherlock Holmes caught a sentimental attachment which you very angry if he has been\n"
     ]
    }
   ],
   "source": [
    "print(markov_output(words, 40))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Improvements\n",
    "\n",
    "One way to improve on the outputs here might be to run the output through a spelling & grammar checking / correction library. This would also allow the puctuation to be stripped out on the input to allow a denser matrix of probabilities (depending on the capabilities of the checker)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
